# Exemplo de configuração para todos os provedores suportados

# Provedor de LLM a ser utilizado: openai, gemini ou ollama
LLM_PROVIDER=openai

# Para simular respostas sem custo (mock)
# LLM_MOCK=true

# --- OpenAI ---
OPENAI_API_KEY=sua-chave-openai-aqui
OPENAI_MODEL=gpt-4o-mini  # (opcional, ex: gpt-4, gpt-3.5-turbo, etc)

# --- Gemini (Google) ---
GEMINI_API_KEY=sua-chave-gemini-aqui

# --- Ollama ---
OLLAMA_API_URL=http://localhost:11434/api/chat
OLLAMA_MODEL=llama3  # (ex: llama3, mistral, phi, etc)

# --- Outras opções globais ---
# (Ajuste o timeout das requisições em milissegundos, se desejar)
# LLM_TIMEOUT=60000

# (Fuso horário para o agendamento cron)
# TIMEZONE=America/Sao_Paulo

# (Agendamento customizado para o cron, ex: toda sexta às 09:00)
# CRON_SCHEDULE=0 9 * * 5

# Ativa o agendamento automático (cron) ao iniciar o projeto
# ENABLE_SCHEDULE=true

# Quantidade de notícias impactantes a serem geradas (padrão: 5)
TOP_NEWS_COUNT=5
